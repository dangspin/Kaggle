{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Classification---Kaggle competition (Part II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this ipython notebook, I will investigate the problem about how to perform feature reductions. The investigation is developed as follows:\n",
    "\n",
    "1. The correlation of features and how to visulize them\n",
    "2. The PCA and feature reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The correlation of features and how to visulize them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, another thanks for the Author of the notebook: https://www.kaggle.com/asparago/3-basic-classifiers-and-features-correlation Federico C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Using Naive Bayes for revealing the feature correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Python visulization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyecharts as pchart\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "## Modelling Algorithms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "## Model preprocess\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import dataset and define the train and test set\n",
    "\n",
    "import os\n",
    "\n",
    "## PATH name definition\n",
    "PATH = os.getcwd()\n",
    "IMAGES = PATH + \"/images\"\n",
    "TRAIN = PATH + \"/train.csv\"\n",
    "TEST = PATH + \"/test.csv\"\n",
    "SAMPLE = PATH + \"sample_submission.csv\"\n",
    "\n",
    "## Get the dataset from the file\n",
    "df = pd.read_csv(TRAIN, sep = ',')\n",
    "df_test = pd.read_csv(TEST, sep = ',')\n",
    "\n",
    "## Label encoder\n",
    "label_fitter = LabelEncoder().fit(df['species'])\n",
    "labels = label_fitter.transform(df['species'])\n",
    "test_ids = df_test.id\n",
    "\n",
    "## Now let's drop the unimportant features\n",
    "df = df.drop(['species', 'id'], axis = 1)\n",
    "df_test = df_test.drop(['id'], axis = 1)\n",
    "\n",
    "## Using stratifiedShuffleSplit to split train and test dataset\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(df, labels)\n",
    "      \n",
    "for train_index, test_index in sss.split(df, labels):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n",
    "    Y_train, Y_test = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set accuracy is: 78.15656565656566%\n",
      "The test set accuracy is: 75.25252525252525%\n"
     ]
    }
   ],
   "source": [
    "## Define Naive Bayes\n",
    "NBC = MultinomialNB()\n",
    "\n",
    "NBC.fit(X_train, Y_train)\n",
    "\n",
    "name = NBC.__class__.__name__\n",
    "\n",
    "train_predictions = NBC.predict(X_test)\n",
    "acc_train = accuracy_score(Y_train, NBC.predict(X_train))\n",
    "acc = accuracy_score(Y_test, train_predictions)\n",
    "\n",
    "print (\"The training set accuracy is: \" + str(acc_train*100)+'%')\n",
    "print (\"The test set accuracy is: \" + str(acc*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "The similar score between the training accuracy and test accuracy proves the point that training and testing dataset obey the same statistical distribution. So the train, test splitting method works quite well in our case. But the low accuracy points out one thing that the assumption of the independent probability is not viable for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The calculation of Pearson coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are evenly distributed among the three big categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['margin' 'shape' 'texture']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "## Check the categories in the columns\n",
    "# nameset = set(re.match(r'([a-z]+)([0-9]+)',i).groups()[0] for i in df.columns)\n",
    "\n",
    "## Alternative solutions\n",
    "nameset = np.unique([re.match(r'([a-z]+)([0-9]+)',i).groups()[0] for i in df.columns])\n",
    "\n",
    "print (nameset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build category names:\n",
    "\n",
    "margin_names = [name for name in df.columns if re.match(r'([a-z]+)([0-9]+)',name).groups()[0] == nameset[0]]\n",
    "shape_names = [name for name in df.columns if re.match(r'([a-z]+)([0-9]+)',name).groups()[0] == nameset[1]]\n",
    "texture_names = [name for name in df.columns if re.match(r'([a-z]+)([0-9]+)',name).groups()[0] == nameset[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pdprint as pp\n",
    "\n",
    "## Build Pearson number within and out category\n",
    "\n",
    "# 1. Within class\n",
    "margin_pearson = [pp.Pearson(df[margin_names[i]], df[margin_names[i+1]]) for i in range(len(margin_names)-1)]\n",
    "shape_names = [pp.Pearson(df[shape_names[i]], df[shape_names[i+1]]) for i in range(len(shape_names)-1)]\n",
    "texture_name = [pp.Pearson(df[texture_names[i]], df[texture_names[i+1]]) for i in range(len(texture_names)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
